{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from khaiii import KhaiiiApi; k = KhaiiiApi()\n",
    "from konlpy.tag import Okt; t = Okt()\n",
    "from konlpy.utils import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./new_train.csv')\n",
    "test = pd.read_csv('../../data/dev.hate.csv')\n",
    "train = raw_data.copy()\n",
    "\n",
    "X_train = train['comments']\n",
    "X_test = test['comments']\n",
    "y_train = train['label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 위한 댓글 데이터(200만개) 로드 후 10만개만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['지드래곤은 난봉꾼이란...댓글도 달렸네 ㅋㅋ 이주연 학창시절 사진 보고 와라. 요즘 웬만한 여자 연예인하고 붙여놔도....미모가 최고였단다.ㅋ 5대 얼짱 출신.',\n",
       " '이주연은 알겠는데 지디는 뭐하는 듣보잡여',\n",
       " '부럽네요. 나도 불과 한달전까진 허니문베이비를 꿈꿨는데 이제 다 부질없네요. 당연히 순결할거라 믿었고 그래서 첫날밤까지 기다려준건데 배신감만 듭니다. 첫날밤 와이프가 피를 안흘렸어요. 처가집식구들이 일부러 절 속였단 생각에 화도나고 어제 처가집가기로 했는데 안간다고 했더니 혼자 울고 갔다와서 지금까지 한마디도 안해요. 이혼하고 싶네요',\n",
       " '\"이주연을 모르는 애들이 많네. 해체된 애프터스쿨 멤버로 당시는 주연이 예명. 인기나 포텐은 안터졌으나, 순수미모만으로는 애프터스쿨에서 원탑이었다. 진짜 자연미인이다.\"',\n",
       " '겨론했으면',\n",
       " '이주연이 아깝다 진심',\n",
       " '방탄은 건드리지말자 인간적으로.. 해외활동 지금주터 시작인데 터지면 진짜 전 세계적으로 활짝 피기도 전에 난리난다.. 국위선양하는 떠오르는 샛별은 제발 건드리지말고.. 탄이들도 만약 연애하더라도 들키지 않길.. ㅠㅠ',\n",
       " '선남선녀의 만남이네요^^',\n",
       " '문재앙 또뭘덥고 싶어서 ㄷㄷㄷ',\n",
       " '주연이 아깝긴해요']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../../korean-hate-speech-detection/unlabeled_comments.txt', 'r') as f:\n",
    "    text = f.readlines()\n",
    "text = [txt.replace(\"\\n\", \"\") for txt in text]\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034837"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cc78560077f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msoynlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# train['comments'] = [repeat_normalize(comment, num_repeats=2) for comment in train['comments']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrepeat_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-cc78560077f2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msoynlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# train['comments'] = [repeat_normalize(comment, num_repeats=2) for comment in train['comments']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrepeat_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/soynlp/normalizer/_normalizer.py\u001b[0m in \u001b[0;36mrepeat_normalize\u001b[0;34m(sent, num_repeats)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrepeat_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_repeats\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeatchars_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\1'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoublespace_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# 특수문자 제거\n",
    "import re\n",
    "def cleanse(text):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', ' ', text)\n",
    "    return text\n",
    "\n",
    "text = [cleanse(txt) for txt in text]\n",
    "\n",
    "# 띄어쓰기\n",
    "from pykospacing import spacing\n",
    "text = [spacing(txt) for txt in text]\n",
    "\n",
    "# 문장 분리\n",
    "import kss\n",
    "# train['comments'] = train['comments'].apply(kss.split_sentences)\n",
    "# train['comments'] = [','.join(map(str, ls)) for ls in train['comments']]\n",
    "text = [kss.split_sentences(txt) for txt in text]\n",
    "\n",
    "# 중복 제거\n",
    "from soynlp.normalizer import *\n",
    "# train['comments'] = [repeat_normalize(comment, num_repeats=2) for comment in train['comments']]\n",
    "text = [repeat_normalize(txt, num_repeats=2) for txt in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = []\n",
    "for sentence in text:\n",
    "    tokenized_data.append(t.morphs(sentence, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = word2vec.Word2Vec(tokenized_data, size=100, window=5, min_count=5, workers=4)\n",
    "embedding.save('./comments100.model')\n",
    "# sentences : 각 문장 마다 하나의 토큰 list를 생성하며 토큰 list의 개수는 문장 개수 n개 만큼 생성하여 sentences에 저장해둠\n",
    "# size : word 벡터 차원\n",
    "# window : 현재 단어와 예측 단어의 최대 거리\n",
    "# negative : 0으로 두면 negative smapling을 하지하지 않으며, 0보다 큰 값이면 negative sampling을 수행함\n",
    "# min_count : min_count의 빈도수보다 낮은 빈도수인 단어는 무시합니다.\n",
    "# worker : 모델 생성시 사용할 쓰레드 개수\n",
    "# sg : sg 값이 1이면 skip-gram이지만 그렇지 않으면 CBOW 알고리즘을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./million_comments.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('탄핵', 0.8041871786117554),\n",
       " ('적폐', 0.7653246521949768),\n",
       " ('국정', 0.7122087478637695),\n",
       " ('근해', 0.6986802816390991),\n",
       " ('쇼통', 0.6714324951171875),\n",
       " ('은박', 0.6534347534179688),\n",
       " ('농단', 0.6520810127258301),\n",
       " ('명박', 0.6471959352493286),\n",
       " ('촛불시위', 0.6338386535644531),\n",
       " ('대통령', 0.6292534470558167),\n",
       " ('방관', 0.6271576285362244),\n",
       " ('적폐임', 0.6238600015640259),\n",
       " ('방심위', 0.6228931546211243),\n",
       " ('정치', 0.622541606426239),\n",
       " ('정부', 0.61871337890625),\n",
       " ('석탄', 0.6154335737228394),\n",
       " ('화이트리스트', 0.6152961254119873),\n",
       " ('지지율', 0.6125301718711853),\n",
       " ('확증', 0.6124624013900757),\n",
       " ('속필', 0.6098626852035522),\n",
       " ('박근혜정부', 0.6084606647491455),\n",
       " ('찬조', 0.6065130233764648),\n",
       " ('부풀리기', 0.6002240180969238),\n",
       " ('언론', 0.5973242521286011),\n",
       " ('척결', 0.5949002504348755),\n",
       " ('봉착', 0.5943487882614136),\n",
       " ('남평문씨', 0.5917057991027832),\n",
       " ('친박', 0.5914238691329956),\n",
       " ('평화상', 0.5912672281265259),\n",
       " ('정으니', 0.5902544856071472)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"문재인\"], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'졸잼',\n",
       " '은혜',\n",
       " '상한',\n",
       " '프라하',\n",
       " '백수',\n",
       " '각양각색',\n",
       " '엇냐',\n",
       " '에궁',\n",
       " '초딩',\n",
       " '헌금',\n",
       " 'ㅋㅋㅁㅊ',\n",
       " '좌빠',\n",
       " '본질',\n",
       " '어벤저스',\n",
       " '3000',\n",
       " '보신탕',\n",
       " '베니',\n",
       " '쉨',\n",
       " '괜찬음',\n",
       " '매매',\n",
       " '답변',\n",
       " '필수',\n",
       " '경사',\n",
       " '갑진',\n",
       " '라곤',\n",
       " '찌끄레기들',\n",
       " '스쿨존',\n",
       " 'ㄱㄹㅇ',\n",
       " '주환',\n",
       " '뭐합',\n",
       " '베이글',\n",
       " '외우다',\n",
       " '살충제',\n",
       " '묘연하다',\n",
       " '괴들',\n",
       " '탈색',\n",
       " '유니클로',\n",
       " '장물아비',\n",
       " '이냐',\n",
       " '라그',\n",
       " '순결하다',\n",
       " '냉정하다',\n",
       " '쾌차',\n",
       " '마지못하다',\n",
       " '중절',\n",
       " '잼있슴',\n",
       " '만들엇네',\n",
       " '러버',\n",
       " '개연',\n",
       " '달자',\n",
       " 'Joong',\n",
       " '카시트',\n",
       " '일리',\n",
       " '폰질',\n",
       " '제기차기',\n",
       " '졸렬하다',\n",
       " '파도',\n",
       " '시멘트',\n",
       " '실전',\n",
       " '앞길',\n",
       " '오바이트',\n",
       " '계산기',\n",
       " 'Are',\n",
       " '인스피릿',\n",
       " '용감한형제',\n",
       " '듀스',\n",
       " '방조',\n",
       " '차이나다',\n",
       " '간척',\n",
       " 'his',\n",
       " '바이킹스',\n",
       " '경매',\n",
       " '다난',\n",
       " '형준',\n",
       " '유쾌하',\n",
       " '포동',\n",
       " '뻔뻔스럽다',\n",
       " '저해',\n",
       " '야인',\n",
       " '생리통',\n",
       " '허위',\n",
       " '는가',\n",
       " '곰탕',\n",
       " '즉시',\n",
       " 'rm',\n",
       " '오심',\n",
       " '한여름',\n",
       " '안식',\n",
       " '진로',\n",
       " '괜찬다',\n",
       " '수지니',\n",
       " '매다',\n",
       " '데이브레이크',\n",
       " '어게인',\n",
       " '렷',\n",
       " '껍질',\n",
       " '모에',\n",
       " '꾐',\n",
       " '김연지',\n",
       " '등하교',\n",
       " '디스커버리',\n",
       " '예언',\n",
       " '논공읍',\n",
       " '광보',\n",
       " '째째하다',\n",
       " '김수현',\n",
       " '흉터',\n",
       " '옌예인',\n",
       " '넥션',\n",
       " '남아도',\n",
       " '청혼',\n",
       " '가트',\n",
       " '매하',\n",
       " '부은',\n",
       " '바나나',\n",
       " '볼땐',\n",
       " '막달',\n",
       " '본바탕',\n",
       " '남창희',\n",
       " '걸캅스',\n",
       " '지구인',\n",
       " '인절미',\n",
       " '순간포착',\n",
       " '오르락내리락',\n",
       " '혈팬',\n",
       " '그르케',\n",
       " '완선',\n",
       " '형돈',\n",
       " '승낙',\n",
       " '바라봄',\n",
       " '결론',\n",
       " '거릴때',\n",
       " 'ac',\n",
       " '43초',\n",
       " '이기다',\n",
       " '도청',\n",
       " '감탄사',\n",
       " '상엽',\n",
       " '쿠사리',\n",
       " '나훈아',\n",
       " '엄말',\n",
       " '답장',\n",
       " '어버이연합',\n",
       " '커트머리',\n",
       " '졸업식',\n",
       " '개입',\n",
       " '트래블러',\n",
       " '박항서',\n",
       " '환생하다',\n",
       " '반품녀',\n",
       " '잉어',\n",
       " '론데',\n",
       " '절데',\n",
       " '묜',\n",
       " '부류',\n",
       " '어쩌시려',\n",
       " 'media',\n",
       " '45억',\n",
       " '갈애',\n",
       " '영양소',\n",
       " '당하다',\n",
       " '대략',\n",
       " '하이퍼',\n",
       " '불법체류자',\n",
       " '억눌리다',\n",
       " '피땀',\n",
       " '엄지',\n",
       " '번더',\n",
       " '떠드',\n",
       " '프로그레시브',\n",
       " 'ㅋㄱㄱㅋ',\n",
       " '깨갱',\n",
       " '때깔',\n",
       " 'ㅁㅈㅎ',\n",
       " '내야',\n",
       " '죄입',\n",
       " '옹심이',\n",
       " '치구',\n",
       " '손해배상',\n",
       " '힘빠지다',\n",
       " '왤다',\n",
       " '개설',\n",
       " '되돌아오다',\n",
       " 'dc',\n",
       " '촛대',\n",
       " '싸이월드',\n",
       " '정은태',\n",
       " '김민지',\n",
       " '불후',\n",
       " '나쵸',\n",
       " 'ㄷㅊ',\n",
       " '님들',\n",
       " '좋겧다',\n",
       " '설자리',\n",
       " '우익',\n",
       " '장끼',\n",
       " '취재',\n",
       " '조씨',\n",
       " '하드웨어',\n",
       " '픕',\n",
       " '주부',\n",
       " '린데',\n",
       " '미국여행',\n",
       " '김정호',\n",
       " '팔로잉',\n",
       " '애기',\n",
       " '오천만원',\n",
       " '검색',\n",
       " '디폴트',\n",
       " '장바구니',\n",
       " '투명하다',\n",
       " '전반',\n",
       " '루비',\n",
       " '경락',\n",
       " '참배',\n",
       " '어좁',\n",
       " '출산율',\n",
       " '뉴규',\n",
       " '국사',\n",
       " '상팔자',\n",
       " '송승현',\n",
       " '모함',\n",
       " '침울하다',\n",
       " '옮기다',\n",
       " '흥보가',\n",
       " '랄때',\n",
       " '원고',\n",
       " 'ㅠㅠㅋ',\n",
       " '개스엠',\n",
       " '식충이',\n",
       " '야후',\n",
       " '습하다',\n",
       " '뭐좀',\n",
       " '로남',\n",
       " '태혜지',\n",
       " '14일',\n",
       " 'LTE',\n",
       " '부동',\n",
       " '뽐',\n",
       " '요것',\n",
       " '변태',\n",
       " '함주',\n",
       " '샤방',\n",
       " '배끼',\n",
       " '1000억원',\n",
       " '거비공',\n",
       " '별개',\n",
       " '우야',\n",
       " '성공하다',\n",
       " '패러글라이딩',\n",
       " '잠',\n",
       " '둘러앉다',\n",
       " 'pt',\n",
       " '맴돔',\n",
       " '제보',\n",
       " '네일아트',\n",
       " '이지선',\n",
       " '파닥파닥',\n",
       " '형탁',\n",
       " '윤도현밴드',\n",
       " '잠실',\n",
       " '똥물',\n",
       " '장소연',\n",
       " '영향',\n",
       " '눈칫밥',\n",
       " '끄덕이다',\n",
       " '슈쥬',\n",
       " '뭘더',\n",
       " '이개',\n",
       " 'behind',\n",
       " 'can',\n",
       " '57',\n",
       " '이경이',\n",
       " '씬나다',\n",
       " '생일도',\n",
       " '고차원',\n",
       " '우륵',\n",
       " '성재기',\n",
       " '김완선',\n",
       " '법시',\n",
       " 'black',\n",
       " '직캠',\n",
       " '집좀',\n",
       " '애나벨',\n",
       " '타쿠',\n",
       " '암기',\n",
       " '김연아',\n",
       " '미션임파서블',\n",
       " '무수',\n",
       " '첫날',\n",
       " '코어',\n",
       " '믈',\n",
       " '병어',\n",
       " '내리다',\n",
       " '당국',\n",
       " '임질',\n",
       " '부주의하다',\n",
       " '대방',\n",
       " '구호',\n",
       " '재규어',\n",
       " '앞장서다',\n",
       " '한예진',\n",
       " 'been',\n",
       " '8회',\n",
       " '안식처',\n",
       " '먹기',\n",
       " '그래그래',\n",
       " '일관',\n",
       " '유재환',\n",
       " '벗겨지다',\n",
       " '교차',\n",
       " 'Vagabond',\n",
       " '음식',\n",
       " '거진',\n",
       " '발매',\n",
       " '팬질',\n",
       " '팟캐스트',\n",
       " '동물',\n",
       " '효성',\n",
       " '럽스타',\n",
       " '소음공해',\n",
       " '렘',\n",
       " '최선',\n",
       " '구원파',\n",
       " '발진',\n",
       " '행동',\n",
       " '양면',\n",
       " '신미',\n",
       " '스뮤',\n",
       " '불어오다',\n",
       " '띠껍',\n",
       " '군산',\n",
       " '살순',\n",
       " '트레일러',\n",
       " '비드',\n",
       " '만을',\n",
       " '쿨러',\n",
       " '채다',\n",
       " '어지르다',\n",
       " '쭈꾸미',\n",
       " '위도',\n",
       " '추바카',\n",
       " '25일',\n",
       " '스크롤',\n",
       " '함박',\n",
       " '오매불망',\n",
       " '여친',\n",
       " '진부하다',\n",
       " 'nct',\n",
       " '새해',\n",
       " '열강',\n",
       " '무도리',\n",
       " '가짐',\n",
       " '대가',\n",
       " '볼떄',\n",
       " '떄',\n",
       " '001',\n",
       " '캐슬',\n",
       " '역량',\n",
       " '키작',\n",
       " '페이',\n",
       " '12억',\n",
       " '월요일',\n",
       " '연대기',\n",
       " '당연하다',\n",
       " 'URL',\n",
       " '중화권',\n",
       " '박완규',\n",
       " '얽매이다',\n",
       " 'death',\n",
       " '떳떳하다',\n",
       " '졍',\n",
       " '풀발',\n",
       " '보고',\n",
       " '박상',\n",
       " '스탠드업',\n",
       " '아스팔트',\n",
       " '고려대',\n",
       " '면상',\n",
       " '갘',\n",
       " '저승사자',\n",
       " '목사',\n",
       " '국자',\n",
       " '템포',\n",
       " '맞붙다',\n",
       " '해처',\n",
       " '꼭지',\n",
       " '뒷이야기',\n",
       " '소릴듣',\n",
       " '09',\n",
       " '소수만',\n",
       " '영남',\n",
       " 'ps',\n",
       " '날조',\n",
       " '껄끄러운',\n",
       " '제리케이',\n",
       " '짜장',\n",
       " '타자',\n",
       " '원문',\n",
       " '쑤시다',\n",
       " '뽀르노',\n",
       " '430억',\n",
       " '주룩주룩',\n",
       " '용구',\n",
       " '오뚜기',\n",
       " '디씨',\n",
       " '비위',\n",
       " '전영록',\n",
       " '히잡',\n",
       " '재밌넼',\n",
       " '이라든지',\n",
       " '말랬는데',\n",
       " '이락',\n",
       " '구유',\n",
       " '성녀',\n",
       " '명동',\n",
       " '무민',\n",
       " '정소영',\n",
       " '문',\n",
       " '햇다',\n",
       " 'kpop',\n",
       " '진중하다',\n",
       " '일비',\n",
       " '강성태',\n",
       " '에드워드',\n",
       " '쫀',\n",
       " '수신료',\n",
       " '빨강',\n",
       " '허지웅',\n",
       " '동학',\n",
       " '액체',\n",
       " '우둔하다',\n",
       " '소비자고발',\n",
       " '괸찮',\n",
       " '어디껀',\n",
       " '꽂히다',\n",
       " '맛사지',\n",
       " '화질',\n",
       " '시너지',\n",
       " '관악산',\n",
       " '책방',\n",
       " '혜지',\n",
       " '안일',\n",
       " '편승',\n",
       " '16회',\n",
       " '홍주',\n",
       " '폐차',\n",
       " '종혁씨',\n",
       " '스타트',\n",
       " '삶의질',\n",
       " '태임',\n",
       " '테이크아웃',\n",
       " '입질',\n",
       " '품일',\n",
       " '진주',\n",
       " '걷기',\n",
       " '자네도',\n",
       " '김혜림',\n",
       " '조수미',\n",
       " '의기소침하다',\n",
       " '융단',\n",
       " '따갑다',\n",
       " '방서',\n",
       " '달라',\n",
       " '이사배',\n",
       " '함유',\n",
       " '경창',\n",
       " '리버풀',\n",
       " '니깐',\n",
       " '인색하다',\n",
       " '여직원',\n",
       " 'J',\n",
       " '불안하다',\n",
       " '과거',\n",
       " 'ㅠㅜㅠㅜ',\n",
       " '박차',\n",
       " '복잡하다',\n",
       " '롤러',\n",
       " '옴짝',\n",
       " '먹는모습',\n",
       " '장점',\n",
       " '지아비',\n",
       " '도균',\n",
       " '안종범',\n",
       " '스릴',\n",
       " 'ck',\n",
       " '이슬',\n",
       " '전만해도',\n",
       " '룸살롱',\n",
       " '식사량',\n",
       " '졸개',\n",
       " '선보다',\n",
       " '송탄',\n",
       " '리코',\n",
       " '흑백',\n",
       " '명언',\n",
       " '보스',\n",
       " '배설',\n",
       " '꿈깨',\n",
       " '선장',\n",
       " '185',\n",
       " '주얼리',\n",
       " '순은',\n",
       " '능국',\n",
       " 'der',\n",
       " '이채널',\n",
       " '함중아',\n",
       " '오우',\n",
       " '하루아침',\n",
       " '선풍기',\n",
       " '용필',\n",
       " '사무엘',\n",
       " 'bmw',\n",
       " '굽이',\n",
       " '드',\n",
       " '깍아',\n",
       " '정형돈',\n",
       " '저고리',\n",
       " '안성훈',\n",
       " '대한민국',\n",
       " '말실수',\n",
       " '국장',\n",
       " '넵둬',\n",
       " '셀',\n",
       " '리파',\n",
       " '전광렬',\n",
       " '쌍꺼풀',\n",
       " '새집',\n",
       " '벼락치기',\n",
       " '전도',\n",
       " '빅픽쳐',\n",
       " '집장',\n",
       " '열댓',\n",
       " '숙지',\n",
       " '먹고살다',\n",
       " '동물병원',\n",
       " '끈기',\n",
       " '뮬란',\n",
       " '알짱대다',\n",
       " '촐랑대다',\n",
       " '댄서',\n",
       " '기린',\n",
       " '맘씨',\n",
       " '개뻔뻔',\n",
       " '말안',\n",
       " '아리까리하다',\n",
       " '빈속',\n",
       " '흡사',\n",
       " '저대로',\n",
       " '소임',\n",
       " '차종',\n",
       " '뭣땜',\n",
       " 'Chen',\n",
       " '독차지',\n",
       " '송은이',\n",
       " '킵',\n",
       " '수량',\n",
       " '버려지다',\n",
       " '승훈',\n",
       " '한집안',\n",
       " '오가다',\n",
       " '혼인',\n",
       " '잿밥',\n",
       " '부흥',\n",
       " '아버',\n",
       " '특종',\n",
       " '조인성',\n",
       " '콘티',\n",
       " '총괄',\n",
       " '바베큐',\n",
       " '사마천',\n",
       " '보필',\n",
       " '바랫',\n",
       " '마중',\n",
       " 'ㅅㅌㅊ',\n",
       " '게런티',\n",
       " '돈값',\n",
       " '치욕',\n",
       " '원흉',\n",
       " '금상첨화',\n",
       " '석회',\n",
       " '블랙',\n",
       " '분단국가',\n",
       " '2조',\n",
       " '김진혁',\n",
       " '무적인',\n",
       " '증인',\n",
       " '얼마간',\n",
       " '18',\n",
       " '왜살',\n",
       " '마주치다',\n",
       " '유익하다',\n",
       " '유은혜',\n",
       " '내자',\n",
       " '술친구',\n",
       " '재도',\n",
       " '개띠',\n",
       " 'past',\n",
       " '댕겨',\n",
       " '지속',\n",
       " '홧이팅',\n",
       " '부창',\n",
       " '대용',\n",
       " '태구',\n",
       " '학자',\n",
       " '주름살',\n",
       " '작일',\n",
       " '절절',\n",
       " '버팀목',\n",
       " '판타지',\n",
       " '동성애자',\n",
       " '인데',\n",
       " '종범',\n",
       " '우르크하이',\n",
       " '치와와',\n",
       " '산도',\n",
       " '곰탱이',\n",
       " '설교',\n",
       " '뽀롱나',\n",
       " '크리스티나',\n",
       " '이다혜',\n",
       " '피빨',\n",
       " '순수',\n",
       " '김수찬',\n",
       " '무팬',\n",
       " '고치다',\n",
       " '보호자',\n",
       " '이다해',\n",
       " '냉시랭',\n",
       " '바부',\n",
       " '다양성',\n",
       " '바퀴',\n",
       " '상두',\n",
       " '박아',\n",
       " '값어치',\n",
       " '사양',\n",
       " '국보',\n",
       " '숲속',\n",
       " '못만드',\n",
       " '인터폴',\n",
       " '이거지',\n",
       " '명정도',\n",
       " '파마',\n",
       " '지식',\n",
       " '광범',\n",
       " '우욱',\n",
       " '초췌',\n",
       " '띨빵하',\n",
       " '넘으면',\n",
       " '블루문',\n",
       " '모르겄다',\n",
       " '우대',\n",
       " '독일인',\n",
       " '몽',\n",
       " '아미가',\n",
       " '양심선언',\n",
       " '타히티',\n",
       " '박경림',\n",
       " '이종석',\n",
       " '망아',\n",
       " '멍청',\n",
       " '강심장',\n",
       " '추적',\n",
       " '꼽아',\n",
       " '와이셔츠',\n",
       " '담하다',\n",
       " '죽엇음',\n",
       " '쌍거',\n",
       " '작태',\n",
       " '참대',\n",
       " '급격하다',\n",
       " '김민규',\n",
       " '뒷담화',\n",
       " '황당',\n",
       " '판권',\n",
       " '함량',\n",
       " '한간',\n",
       " '슈퍼볼',\n",
       " '실감',\n",
       " '에러',\n",
       " '레걸',\n",
       " '가물',\n",
       " '그린랜턴',\n",
       " '잘됫으',\n",
       " '공격성',\n",
       " '외교',\n",
       " '비주',\n",
       " '봉고차',\n",
       " '두',\n",
       " '프시',\n",
       " '내주다',\n",
       " '백아연',\n",
       " 'ARMY',\n",
       " '고령',\n",
       " '역할',\n",
       " '에어부산',\n",
       " '눈빛',\n",
       " '술버릇',\n",
       " '재무',\n",
       " '돈버는건데',\n",
       " '프로모션',\n",
       " 'trust',\n",
       " '간신',\n",
       " '약지',\n",
       " '소주',\n",
       " '허위사실유포죄',\n",
       " '적적하다',\n",
       " '자제시키다',\n",
       " '상폐남',\n",
       " 'drama',\n",
       " '꼬봉',\n",
       " '치명',\n",
       " '카니발',\n",
       " '무적',\n",
       " '왕권',\n",
       " '종일',\n",
       " '신봉',\n",
       " '조세호',\n",
       " '번것',\n",
       " '다나',\n",
       " '송이버섯',\n",
       " '해먹',\n",
       " '훌룡',\n",
       " '흥얼거리다',\n",
       " '누누',\n",
       " '종치',\n",
       " '좀바',\n",
       " '육박',\n",
       " 'jbj',\n",
       " 'Jtbc',\n",
       " '버',\n",
       " '난민',\n",
       " '유피',\n",
       " '일전',\n",
       " '앙탈',\n",
       " '불끈',\n",
       " '타네',\n",
       " '밸',\n",
       " '연한',\n",
       " '주간',\n",
       " '시부모',\n",
       " '조카',\n",
       " '리액션',\n",
       " '류머연',\n",
       " '미주신경',\n",
       " '추서',\n",
       " '무안',\n",
       " '띄다',\n",
       " '심플',\n",
       " '성혜',\n",
       " '영화감독',\n",
       " '총선',\n",
       " '개비',\n",
       " '잘불르다',\n",
       " '박준범',\n",
       " '진회',\n",
       " '식',\n",
       " '돌아서다',\n",
       " '따',\n",
       " '경미하다',\n",
       " '몫',\n",
       " '상품화',\n",
       " '사모펀드',\n",
       " '맘',\n",
       " '카운트다운',\n",
       " '품격',\n",
       " '지대',\n",
       " '3000억',\n",
       " '안준영',\n",
       " '헬스하',\n",
       " '살',\n",
       " '노후',\n",
       " '나하시',\n",
       " '누굴',\n",
       " '쭉정이',\n",
       " '놈놈놈',\n",
       " '보수',\n",
       " '노홍철',\n",
       " '도형',\n",
       " '굿판',\n",
       " '부글',\n",
       " '자업자득',\n",
       " '뿡뿡이',\n",
       " '주어지다',\n",
       " '출판',\n",
       " '다반',\n",
       " '셧습니',\n",
       " '빡머가리',\n",
       " '톡',\n",
       " '난무',\n",
       " '지만',\n",
       " '미화원',\n",
       " '숙성',\n",
       " '작업실',\n",
       " '겁내',\n",
       " 'ㅇㅁㅇ',\n",
       " '스카이',\n",
       " '나사',\n",
       " '투신',\n",
       " '선행',\n",
       " '유정',\n",
       " '뚱',\n",
       " '쁨',\n",
       " '웅애',\n",
       " '일종',\n",
       " '킬스위치',\n",
       " '대종상',\n",
       " '사진',\n",
       " '절교',\n",
       " '젤꼴',\n",
       " '진해',\n",
       " '하늘색',\n",
       " '노리개',\n",
       " '고화질',\n",
       " '충견',\n",
       " '엑스',\n",
       " '굴렸',\n",
       " '할아버지',\n",
       " 'XXX',\n",
       " '정대세',\n",
       " '불투명',\n",
       " '힌트',\n",
       " '트레이드',\n",
       " '으니',\n",
       " '주거침입',\n",
       " '데인',\n",
       " '용병',\n",
       " '자책',\n",
       " '수캐',\n",
       " '갈갈',\n",
       " '선즙',\n",
       " '화구',\n",
       " '46년',\n",
       " '밑바탕',\n",
       " '97년',\n",
       " '육중',\n",
       " '승락',\n",
       " '보통사람',\n",
       " '직업',\n",
       " '한의원',\n",
       " '망나니',\n",
       " '일부다처제',\n",
       " '야릇하다',\n",
       " '서병기',\n",
       " '탐사',\n",
       " '도찰',\n",
       " '얼치기',\n",
       " '표적',\n",
       " '찌그리다',\n",
       " '볼펜',\n",
       " '시공',\n",
       " '생인',\n",
       " '대별',\n",
       " 'kbs',\n",
       " '청소부',\n",
       " '모서리',\n",
       " '이지',\n",
       " '섬나라',\n",
       " '전부일',\n",
       " '만족',\n",
       " '50년',\n",
       " '카지노',\n",
       " '북해',\n",
       " '앞장',\n",
       " '처마',\n",
       " '룸빵',\n",
       " '씹선비',\n",
       " '조물',\n",
       " '발뺌',\n",
       " '고전',\n",
       " '길영',\n",
       " '로린',\n",
       " '사고팔다',\n",
       " '성신여대',\n",
       " '깨끝',\n",
       " '김사랑',\n",
       " '인도사람',\n",
       " 'ㅠㅇㅠ',\n",
       " '예절',\n",
       " '수지',\n",
       " '밑밥',\n",
       " '드럼통',\n",
       " '생긱',\n",
       " '박정철',\n",
       " 'ㄱㅇ',\n",
       " '밤길',\n",
       " '상황보고',\n",
       " '부족',\n",
       " '부유하다',\n",
       " '김삿갓',\n",
       " '이산',\n",
       " '1000년',\n",
       " 'these',\n",
       " '벽화',\n",
       " '재밋는',\n",
       " '13억',\n",
       " '시민',\n",
       " '주님',\n",
       " '우연',\n",
       " 'vos',\n",
       " '돼지고기',\n",
       " '서브보컬',\n",
       " '발해',\n",
       " '합리화',\n",
       " '저건',\n",
       " '발좀',\n",
       " '글코',\n",
       " '공카',\n",
       " '안궁굼',\n",
       " '화단',\n",
       " '껑충',\n",
       " '빵떡',\n",
       " '페치',\n",
       " '늦잠',\n",
       " '니뽄',\n",
       " '틱틱대',\n",
       " '라는',\n",
       " '잘생겻으',\n",
       " '자살률',\n",
       " '호야',\n",
       " '저쩌',\n",
       " '에누구',\n",
       " '쫄따구',\n",
       " '사마리아',\n",
       " '광해군',\n",
       " '전업',\n",
       " '만나다',\n",
       " '반려견',\n",
       " '패치',\n",
       " '턱수염',\n",
       " '비녀',\n",
       " '금연',\n",
       " '분배',\n",
       " '우쭐',\n",
       " '눙물',\n",
       " '다운로드',\n",
       " '파경',\n",
       " '이듬',\n",
       " '이벤트',\n",
       " '졸피뎀',\n",
       " '무시무시하다',\n",
       " 'table',\n",
       " '는걸',\n",
       " '사래',\n",
       " '검법',\n",
       " '듣',\n",
       " '비행기',\n",
       " '임태경',\n",
       " 'ymc',\n",
       " '암투',\n",
       " '상응',\n",
       " '진실성',\n",
       " '내해',\n",
       " '자리야',\n",
       " '이도',\n",
       " '비좀',\n",
       " '유능하다',\n",
       " '랄것',\n",
       " '꼬리',\n",
       " '콧구멍',\n",
       " '빳빳',\n",
       " '재밋었어',\n",
       " 'ㅋㅌㅋ',\n",
       " '발병',\n",
       " '미정',\n",
       " '이소라',\n",
       " '몸통',\n",
       " '미루다',\n",
       " '레알마드리드',\n",
       " '극구',\n",
       " '안시',\n",
       " '입히다',\n",
       " '2011년',\n",
       " '간걸',\n",
       " '말씀',\n",
       " '켜지다',\n",
       " 'public',\n",
       " '필요없다',\n",
       " '존버합니',\n",
       " '1020',\n",
       " '중이',\n",
       " '묶인',\n",
       " '황소영',\n",
       " '캐디',\n",
       " '법원행정처',\n",
       " '비열하다',\n",
       " '불명예',\n",
       " '동료',\n",
       " '업로드',\n",
       " '친고죄',\n",
       " '부각',\n",
       " '눔',\n",
       " '피잣',\n",
       " '이골',\n",
       " '외멤퀴들',\n",
       " '소심하다',\n",
       " '정창영',\n",
       " '경쾌하다',\n",
       " '걸핏하면',\n",
       " '나왓던',\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros(100, dtype=np.float32)\n",
    "    num_words = 0\n",
    "    \n",
    "    # 어휘 사전 준비\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words = 1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "            \n",
    "    # 문장의 단어 수만큼 나누어 단어 벡터의 평균값을 문장 벡터로 함\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07574642, -0.0988207 , -0.48576212, -0.4776301 ,  1.0557545 ,\n",
       "        1.638185  , -0.52016985, -0.10827143, -0.6731411 ,  0.5465597 ,\n",
       "       -1.2510335 ,  0.7781881 ,  0.86021054, -1.5637627 , -1.1958218 ,\n",
       "        0.48384106, -0.5856546 ,  0.3942331 ,  0.58857167, -0.8910247 ,\n",
       "       -0.86850727,  1.3836409 ,  0.14626695,  0.72884285,  0.14109324,\n",
       "       -0.9455564 , -1.2405579 , -0.9072786 ,  0.1578528 , -0.3662238 ,\n",
       "        0.9585849 ,  0.27965495, -0.5208655 ,  0.61863285,  0.80589837,\n",
       "       -0.7552631 , -0.7169019 , -0.13069305,  0.49273053,  0.58437   ,\n",
       "       -0.9490637 ,  0.21465805, -1.1149619 , -2.0163708 , -0.53309685,\n",
       "        1.2184591 , -0.40251458, -1.573397  ,  0.21312025, -0.6301665 ,\n",
       "       -0.09679359, -0.5476607 , -1.2148906 ,  0.9498155 ,  1.4136295 ,\n",
       "       -0.6151596 , -0.06888026, -0.26032174, -0.1605458 ,  1.1390946 ,\n",
       "        0.05094002, -0.39497793, -0.60097647, -0.42819184, -0.88350314,\n",
       "       -0.45874068,  0.06497264,  1.0659873 ,  0.55221194,  0.5469426 ,\n",
       "        0.96317333, -0.6499646 , -1.0855448 , -0.46252096,  1.7661914 ,\n",
       "       -0.51355326,  0.35093284, -0.7581463 , -0.70553327,  0.7492883 ,\n",
       "        0.84961945, -0.6709137 , -0.9692545 , -0.4976806 ,  0.39489126,\n",
       "       -0.7362197 ,  0.7014364 , -0.2662686 , -0.26643842,  0.7533455 ,\n",
       "        1.4570553 , -0.91731364, -0.7014527 , -0.1710713 ,  0.13824178,\n",
       "       -1.6610003 , -1.7594907 , -1.3787923 ,  0.22260062,  0.9479208 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features('아 진짜 짜증난다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(comments):\n",
    "    dataset = []\n",
    "    \n",
    "    for s in comments:\n",
    "        dataset.append(get_features(s))\n",
    "        \n",
    "    commentFeatureVecs = np.stack(dataset)\n",
    "    return commentFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial', class_weight='balanced')\n",
    "\n",
    "X_train_vecs = get_dataset(X_train)\n",
    "lr.fit(X_train_vecs, y_train)\n",
    "\n",
    "X_test_vecs = get_dataset(X_test)\n",
    "\n",
    "preds = lr.predict(X_test_vecs)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5520169851380042 F1 Score : 0.5457512516497584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(\"Accuracy : {}\".format(accuracy_score(preds, y_test)),\n",
    "    \"F1 Score : {}\".format(f1_score(preds, y_test, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지현우 나쁜놈</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>설마 ㅈ 현정 작가 아니지??</td>\n",
       "      <td>hate</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>지현우 범죄 저지르지 않았나요?</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>여자인생 망칠 일 있나 ㅋㅋ</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments      label      preds\n",
       "0                          송중기 시대극은 믿고본다. 첫회 신선하고 좋았다.       none       none\n",
       "1                                              지현우 나쁜놈  offensive       none\n",
       "2           알바쓰고많이만들면되지 돈욕심없으면골목식당왜나온겨 기댕기게나하고 산에가서팔어라       hate       hate\n",
       "3                                     설마 ㅈ 현정 작가 아니지??       hate  offensive\n",
       "4    이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...  offensive       none\n",
       "..                                                 ...        ...        ...\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive       none\n",
       "467                                    여자인생 망칠 일 있나 ㅋㅋ       hate       hate\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive       none\n",
       "469  할매젖x, 뱃살x, 몸매 s라인, 유륜은 적당해야됨(너무크거나 너무 작아도 x), ...       hate       hate\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none       hate\n",
       "\n",
       "[471 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['preds'] = preds\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지현우 나쁜놈</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>설마 ㅈ 현정 작가 아니지??</td>\n",
       "      <td>hate</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>알았어 그만</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>아c발 어쩌라고 뭔기사가계속나오냐</td>\n",
       "      <td>hate</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>강용석도 찌질하네 과거들추기는 추하다</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>지겹이 이프로 그만하자 작가야</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>지현우 범죄 저지르지 않았나요?</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?</td>\n",
       "      <td>offensive</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments      label      preds\n",
       "1                                              지현우 나쁜놈  offensive       none\n",
       "3                                     설마 ㅈ 현정 작가 아니지??       hate  offensive\n",
       "4    이미자씨 송혜교씨 돈이 그리 많으면 탈세말고 그돈으로 평소에 불우이웃에게 기부도 좀...  offensive       none\n",
       "8                                               알았어 그만  offensive       none\n",
       "11                                  아c발 어쩌라고 뭔기사가계속나오냐       hate  offensive\n",
       "..                                                 ...        ...        ...\n",
       "463                               강용석도 찌질하네 과거들추기는 추하다  offensive       none\n",
       "464                                   지겹이 이프로 그만하자 작가야  offensive       none\n",
       "466                                  지현우 범죄 저지르지 않았나요?  offensive       none\n",
       "468            근데 전라도에서 사고가 났는데 굳이 서울까지 와서 병원에 가느 이유는?  offensive       none\n",
       "470  남자가 잘못한거라면... 반성도 없다면...나였다면 ... 여자처럼 아주 못되게 할...       none       hate\n",
       "\n",
       "[211 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['label'] != test['preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble                import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.model_selection         import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics                 import accuracy_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.pipeline                import Pipeline\n",
    "from sklearn.svm                     import SVC\n",
    "from lightgbm                        import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(), LogisticRegression(), SVC(), LGBMClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Accuracy : 0.4437367303609342\n",
      "F1 Score : 0.40657653491000234\n",
      "\n",
      "LogisticRegression()\n",
      "Accuracy : 0.5201698513800425\n",
      "F1 Score : 0.49559043496640337\n",
      "\n",
      "SVC()\n",
      "Accuracy : 0.4819532908704883\n",
      "F1 Score : 0.451411480568302\n",
      "\n",
      "LGBMClassifier()\n",
      "Accuracy : 0.5031847133757962\n",
      "F1 Score : 0.48263028571247757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    vec_model = model\n",
    "\n",
    "    vec_model.fit(X_train_vecs, y_train)\n",
    "    preds = vec_model.predict(X_test_vecs)\n",
    "\n",
    "    print(model, \"\\n\",\n",
    "          \"Accuracy : {}\".format(accuracy_score(preds, y_test)), '\\n'\n",
    "          \"F1 Score : {}\".format(f1_score(preds, y_test, average='macro')), '\\n', sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./comments100.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./new_train.csv')\n",
    "dev = pd.read_csv('../../data/dev.hate.csv')\n",
    "test = pd.read_csv('../../data/test.hate.no_label.csv')\n",
    "train = pd.concat([train, dev], axis=0)\n",
    "X_train = train['comments']\n",
    "X_test = test['comments']\n",
    "y_train = train['label']\n",
    "# y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vecs = get_dataset(X_train)\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial', class_weight='balanced')\n",
    "lr.fit(X_train_vecs, y_train)\n",
    "\n",
    "X_test_vecs = get_dataset(X_test)\n",
    "\n",
    "preds = lr.predict(X_test_vecs)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>장현승 얘도 참 이젠 짠하다...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       comments label\n",
       "0  ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ  none\n",
       "1                                 둘다 넘 좋다~행복하세요  none\n",
       "2          근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데  none\n",
       "3         원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요  none\n",
       "4                            장현승 얘도 참 이젠 짠하다...  none"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = preds\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_format(df):\n",
    "    df['label'][df['label'] == 'none'] = 0\n",
    "    df['label'][df['label'] == 'offensive'] = 1\n",
    "    df['label'][df['label'] == 'hate'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>장현승 얘도 참 이젠 짠하다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>난 조보아 이뻐서 보는데 백종원 관심무</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments label\n",
       "0         ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ     0\n",
       "1                                        둘다 넘 좋다~행복하세요     0\n",
       "2                 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데     0\n",
       "3                원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요     0\n",
       "4                                   장현승 얘도 참 이젠 짠하다...     0\n",
       "..                                                 ...   ...\n",
       "969                     대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹     2\n",
       "970  성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...     2\n",
       "971  분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...     2\n",
       "972                               입에 손가릭이 10개 있으니 징그럽다     2\n",
       "973                              난 조보아 이뻐서 보는데 백종원 관심무     0\n",
       "\n",
       "[974 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_format(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./0117_jc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
